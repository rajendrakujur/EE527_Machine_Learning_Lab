{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvKkaQdZKKU2"
   },
   "source": [
    "# Assignment 07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My1HNfHxKS2l"
   },
   "source": [
    "## Group Members\n",
    "1. RAJENDRA KUJUR (214161008)\n",
    "2. ROHIT RAJ SINGH CHAUHAN (214161009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EQyMNl_9KLb9"
   },
   "outputs": [],
   "source": [
    "# importing all necessary libraries\n",
    "from numpy.linalg import eig\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOOzZUrU8AxA"
   },
   "source": [
    "### Reading the data and making it ready to perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "4QXuaWdbxQyu",
    "outputId": "1541ce9b-16ff-451d-a5b4-e74abdb854f6"
   },
   "outputs": [],
   "source": [
    "# df reads the first column as labels\n",
    "df = pd.read_csv('./train.csv')\n",
    "\n",
    "# taking first row as test data\n",
    "test_df = df.iloc[0,:]\n",
    "test_label = test_df['label']\n",
    "test_df = test_df[1:].to_numpy().reshape(1, -1)\n",
    "\n",
    "labels = df[df.columns[0]]\n",
    "\n",
    "# delete the first column i.e. the labels\n",
    "df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "X = df\n",
    "X.head(5)\n",
    "# Calculate mean\n",
    "mu = np.mean(X, axis =0)\n",
    "mu.shape\n",
    "mu = mu.to_numpy().reshape((1,784))\n",
    "\n",
    "# mean adjusted\n",
    "Y = X - mu\n",
    "\n",
    "# calculate covariance matrix\n",
    "C = np.dot(Y.T, Y)\n",
    "C = np.cov(Y.T)\n",
    "EigenValues, EigenVector = eig(C)\n",
    "\n",
    "# sort and reverse the eigen values indices\n",
    "indices = np.flipud(np.argsort(EigenValues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ooq2dB9k72Z8"
   },
   "source": [
    "### function that returns the precision % after giving certain parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GhDnhBQK66vR"
   },
   "outputs": [],
   "source": [
    "def performanceEvaluation(PCA_d, depth, leaf_threshold, top_k):\n",
    "  # select first 300 eigen values and corresponding eigen vectors\n",
    "  A = np.array([EigenValues[indices[i]] for i in range(PCA_d)])\n",
    "  E = np.array([EigenVector[indices[i]] for i in range(PCA_d)])\n",
    "\n",
    "  # dimension reduced matrix\n",
    "  D = np.dot(Y, E.T)\n",
    "  \n",
    "  # find index with maximum variance and calculate its median\n",
    "  index = np.argmax(np.var(D, axis = 0))\n",
    "  column = np.array([D[i][index] for i in range(len(D))])\n",
    "  mvalue = np.median(column)\n",
    "\n",
    "  # make a node with data at 0th index, index with maxvariance at 1st index, median value (hash function) at 2nd index\n",
    "  node = [D, index, mvalue, labels]\n",
    "  f = [node]\n",
    "\n",
    "  r = 2**(depth-1)-1\n",
    "\n",
    "  # continue untill we make it to the leaf node\n",
    "  for index_1 in range(r):\n",
    "    lchild = []\n",
    "    rchild = []\n",
    "    l_label = []\n",
    "    r_label = []\n",
    "    # extract values from node\n",
    "    matrix = f[index_1][0]\n",
    "    check_index = f[index_1][1]\n",
    "    check_value = f[index_1][2]\n",
    "    mat_label = f[index_1][3]\n",
    "      \n",
    "    # check for each matrix's pixel if its value greater than median value then move it to right child else left child\n",
    "    for index_2 in range(len(matrix)):\n",
    "      if matrix[index_2][check_index] < check_value:\n",
    "        lchild.append(matrix[index_2])\n",
    "        l_label.append(mat_label[index_2])\n",
    "      else:\n",
    "        rchild.append(matrix[index_2])\n",
    "        r_label.append(mat_label[index_2])\n",
    "\n",
    "    lchild = np.array(lchild)\n",
    "    rchild = np.array(rchild)\n",
    "    l_label = np.array(l_label)\n",
    "    r_label = np.array(r_label)\n",
    "\n",
    "    m_thres = 20\n",
    "\n",
    "    # make a node as left child with data at 0th index, index with maxvariance at 1st index, median value (hash function) at 2nd index\n",
    "    # calculate max variance index and median and make a node and append it to the hash function array\n",
    "    if len(lchild) == 0 or len(lchild) < m_thres:\n",
    "      index_lchild = -1 \n",
    "      median_lchild = -1\n",
    "      label_l = -1\n",
    "    else:\n",
    "      index_lchild = np.argmax(np.var(lchild, axis = 0))\n",
    "      column = np.array([D[i][index] for i in range(len(lchild))])\n",
    "      median_lchild = np.median(column)\n",
    "\n",
    "    left_child = [lchild, index_lchild, median_lchild, l_label]\n",
    "\n",
    "      # make a node as right child with data at 0th index, index with maxvariance at 1st index, median value (hash function) at 2nd index\n",
    "      # calculate max variance index and median and make a node and append it to the hash function array\n",
    "    if len(rchild) == 0 or len(lchild) < m_thres:\n",
    "      index_rchild = -1 \n",
    "      median_rchild = -1\n",
    "      label_1 = -1\n",
    "    else:\n",
    "      index_rchild = np.argmax(np.var(rchild, axis = 0))\n",
    "      column = np.array([D[i][index] for i in range(len(rchild))])\n",
    "\n",
    "      median_rchild = 0\n",
    "      label_r = labels[index_rchild]\n",
    "    right_child = [rchild, index_rchild, median_rchild, r_label]\n",
    "    \n",
    "    f.append(left_child)\n",
    "    f.append(right_child)\n",
    "\n",
    "  # adjust test data according to need\n",
    "  y = test_df - mu\n",
    "  y = np.matmul(y, E.T)\n",
    "\n",
    "  # Searching in KDTree\n",
    "  KDTree = f \n",
    "  max_index = 2**(depth)-1\n",
    "  current_index = 0\n",
    "\n",
    "  while ((current_index*2+1) < max_index) and (KDTree[current_index*2+1][1]!= -1):\n",
    "    if y[0, KDTree[current_index][1]] < KDTree[current_index][2]:\n",
    "      current_index = current_index*2 + 1\n",
    "    else:\n",
    "      current_index = current_index*2 + 2\n",
    "\n",
    "  distance = []\n",
    "  for i in range(len(KDTree[current_index][0])):\n",
    "    distance.append(np.linalg.norm(KDTree[current_index][0][i, :] - y))\n",
    "\n",
    "  ind = np.argpartition(distance, top_k)[ :top_k]\n",
    "  final_label = np.array(KDTree[current_index][3])[ind]\n",
    "\n",
    "  # calculate precision according to given formula\n",
    "  precision = (np.sum((final_label == test_label).astype(int))/top_k)*100\n",
    "  return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mn-2V71p8Lq2"
   },
   "source": [
    "## Test Case 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "L4WYYq2P5iSA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision with given parameters : 95.0%\n"
     ]
    }
   ],
   "source": [
    "PCA_d = 48\n",
    "max_depth = 20\n",
    "leaf_threshold = 5000\n",
    "top_k = 20\n",
    "searchPrecision = performanceEvaluation(PCA_d, max_depth, leaf_threshold, top_k)\n",
    "print(f'Precision with given parameters : {searchPrecision}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iE3XcmiV8RZy"
   },
   "source": [
    "## Test Case 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mc23iTYK8qGr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision with given parameters : 100.0%\n"
     ]
    }
   ],
   "source": [
    "PCA_d = 300\n",
    "max_depth = 15\n",
    "leaf_threshold = 2500\n",
    "top_k = 50\n",
    "searchPrecision = performanceEvaluation(PCA_d, max_depth, leaf_threshold, top_k)\n",
    "print(f'Precision with given parameters : {searchPrecision}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFYiLMIG8RiP"
   },
   "source": [
    "## Test Case 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XCU3zjbq8uQ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision with given parameters : 100.0%\n"
     ]
    }
   ],
   "source": [
    "PCA_d = 120\n",
    "max_depth = 9\n",
    "leaf_threshold = 2890\n",
    "top_k = 8\n",
    "searchPrecision = performanceEvaluation(PCA_d, max_depth, leaf_threshold, top_k)\n",
    "print(f'Precision with given parameters : {searchPrecision}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLqV9YB08ZFm"
   },
   "source": [
    "## Test Case 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xch2HuCX6idf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision with given parameters : 93.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "PCA_d = 70\n",
    "max_depth = 12\n",
    "leaf_threshold = 4000\n",
    "top_k = 30\n",
    "searchPrecision = performanceEvaluation(PCA_d, max_depth, leaf_threshold, top_k)\n",
    "print(f'Precision with given parameters : {searchPrecision}%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "214161008_214161009.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
